{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This part of the exam will test your skills maneuvering in Pandas, as well as your ability to think of ways to improve computing and memory efficiency.\n",
    "\n",
    "The dataset used in these exercises, [\"Offensive Baseball Stats Through 2016\"](https://www.kaggle.com/baseballstatsonline/offensive-baseball-stats-through-2016), Version 1, is from Kaggle user baseballstatsonline.com. The dataset is a fairly rich set of players and statistics, but for the purposes of these exercises you do not need to know anything in particular about the columns' meaning unless it is otherwise explained below. The dataset has been modified slightly for the purpose of some exercises. \n",
    "\n",
    "Run the following code cell to download the data and create some necessary functions. Good luck!\n",
    "\n",
    "**Note:** If you are running this notebook locally please make sure you run the same version of pandas as in Vocareum enviroment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player Name</th>\n",
       "      <th>playerID</th>\n",
       "      <th>yearID</th>\n",
       "      <th>stint</th>\n",
       "      <th>teamID</th>\n",
       "      <th>name</th>\n",
       "      <th>park</th>\n",
       "      <th>lgID</th>\n",
       "      <th>G</th>\n",
       "      <th>AB</th>\n",
       "      <th>...</th>\n",
       "      <th>birthCountry</th>\n",
       "      <th>birthState</th>\n",
       "      <th>birthDay</th>\n",
       "      <th>birthMonth</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>bats</th>\n",
       "      <th>200HitSeason</th>\n",
       "      <th>Decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carroll</td>\n",
       "      <td>carroch01</td>\n",
       "      <td>1884-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>WSU</td>\n",
       "      <td>Washington Nationals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UA</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gavern</td>\n",
       "      <td>gaver01</td>\n",
       "      <td>1874-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BR2</td>\n",
       "      <td>Brooklyn Atlantics</td>\n",
       "      <td>Union Grounds</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>McRemer</td>\n",
       "      <td>mcrem01</td>\n",
       "      <td>1884-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>WSU</td>\n",
       "      <td>Washington Nationals</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sterling</td>\n",
       "      <td>sterljo01</td>\n",
       "      <td>1890-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>PH4</td>\n",
       "      <td>Philadelphia Athletics</td>\n",
       "      <td>Jefferson Street Grounds</td>\n",
       "      <td>AA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. J. Ellis</td>\n",
       "      <td>ellisaj01</td>\n",
       "      <td>1/1/14</td>\n",
       "      <td>1</td>\n",
       "      <td>LAN</td>\n",
       "      <td>Los Angeles Dodgers</td>\n",
       "      <td>Dodger Stadium</td>\n",
       "      <td>NL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>MO</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>6.166666</td>\n",
       "      <td>R</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Player Name   playerID      yearID  stint teamID                    name  \\\n",
       "0      Carroll  carroch01  1884-01-01      1    WSU    Washington Nationals   \n",
       "1       Gavern    gaver01  1874-01-01      1    BR2      Brooklyn Atlantics   \n",
       "2      McRemer    mcrem01  1884-01-01      1    WSU    Washington Nationals   \n",
       "3     Sterling  sterljo01  1890-01-01      1    PH4  Philadelphia Athletics   \n",
       "4  A. J. Ellis  ellisaj01      1/1/14      1    LAN     Los Angeles Dodgers   \n",
       "\n",
       "                       park lgID  G  AB   ...    birthCountry  birthState  \\\n",
       "0                       NaN   UA  4  16   ...             NaN         NaN   \n",
       "1             Union Grounds  NaN  1   0   ...             NaN         NaN   \n",
       "2                       NaN   UA  1   0   ...             NaN         NaN   \n",
       "3  Jefferson Street Grounds   AA  1   0   ...             NaN         NaN   \n",
       "4            Dodger Stadium   NL  0   0   ...             USA          MO   \n",
       "\n",
       "   birthDay  birthMonth  birthYear  Weight    Height  bats  200HitSeason  \\\n",
       "0         0           0          0       0  0.000000   NaN             0   \n",
       "1         0           0          0       0  0.000000   NaN             0   \n",
       "2         0           0          0       0  0.000000   NaN             0   \n",
       "3         0           0          0       0  0.000000   NaN             0   \n",
       "4         9           4       1981       0  6.166666     R             0   \n",
       "\n",
       "   Decade  \n",
       "0    1800  \n",
       "1    1800  \n",
       "2    1800  \n",
       "3    1800  \n",
       "4    2020  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cse6040utils import canonicalize_tibble, tibbles_are_equivalent    \n",
    "\n",
    "DATA_PATH = \"../resource/asnlib/publicdata/\"  # This path is hard-coded to work on Vocareum only\n",
    "baseball = pd.read_csv('{}mlb_off_stats_modified.csv'.format(DATA_PATH),header=0)\n",
    "baseball_test = baseball.iloc[np.arange(1, baseball.shape[0], 200)]\n",
    "baseball.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "First things first, let's delete unnecessary columns.\n",
    "\n",
    "**Exercise 0** (1 point): Complete the `remove_redundant_columns` function that takes dataframe `df` and returns a _**new**_ dataframe  _excluding_ the following columns:\n",
    "- Any column with the word 'Career' in it's name\n",
    "- Any column with the string 'birth' in it's name\n",
    "- 200HitSeason, Decade, Player Name, name, park, lgID, bats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colnames = ['Player Name', 'playerID', 'yearID', 'stint', 'teamID', 'name', 'park', 'lgID', 'G', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'SB', 'CS', 'BB', 'SO', 'IBB', 'HBP', 'SH', 'SF', 'GIDP', '1B', 'PA', 'BA', 'OBP', 'TB', 'SLG', 'OPS', 'ISO', 'BB%', 'K%', 'BB/K', 'BAPIP', 'SB%', 'Weighted162Factor', 'R Career', 'G Career', '1B Career', '2B Career', 'HR Career', 'SB Career', 'CS Career', 'BB Career', 'SO Career', 'IBB Career', 'HBP Career', 'SH Career', 'SF Career', 'GIDP Career', 'AB Career', 'PA Career', 'BA Career', 'OBP Career', 'TB Career', 'SLG Career', 'OPS Career', 'ISO Career', 'BB% Career', 'K% Career', 'BAPIP Career', 'BB/K Career', 'SB% Career', 'birthCity', 'birthCountry', 'birthState', 'birthDay', 'birthMonth', 'birthYear', 'Weight', 'Height', 'bats', '200HitSeason', 'Decade', '200HitSeason', 'Decade', 'Player Name', 'name', 'park', 'lgID', 'bats']\n",
    "\n",
    "def remove_redundant_columns(df):\n",
    "    #Copy dataframe\n",
    "    df_copy=df.copy()\n",
    "    \n",
    "    #Construct list of columns to remove\n",
    "    remove=[col for col in df_copy.columns if 'Career' in col or 'birth' in col]\n",
    "    for item in ['200HitSeason', 'Decade', 'Player Name', 'name', 'park', 'lgID', 'bats']:\n",
    "        remove.append(item)\n",
    "    #print(remove)\n",
    "    df_copy.drop(remove, axis=1, inplace=True)\n",
    "    #print('df_copy.columns: ', df_copy.columns)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "To test your solution we have created a data frame `baseball_test` which is a much smaller sample of the orginial dataframe `baseball`. We also provided how the output for `remove_redundant_columns(baseball_test)` should look like in data-frame `df_ex0_soln_instructor`. \n",
    "\n",
    "**Note**: The below test case is designed just for the purpose of debugging and will not be used for grading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "remove_redundant_columns_dummy",
     "locked": true,
     "points": "0",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# (0 Points) `remove_redundant_columns_dummy`: Test cell 1\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "\n",
    "df_ex0_soln_instructor = canonicalize_tibble(pd.read_csv('ex0_soln.csv'))\n",
    "df_ex0_soln_yours = canonicalize_tibble(remove_redundant_columns(baseball_test))\n",
    "\n",
    "assert type(df_ex0_soln_yours) == type(df_ex0_soln_instructor), 'Your output does not return a pandas dataframe'\n",
    "assert_frame_equal(df_ex0_soln_instructor, df_ex0_soln_yours)\n",
    "\n",
    "print('Passed!')\n",
    "\n",
    "del df_ex0_soln_instructor\n",
    "del df_ex0_soln_yours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Testing your solution on the original dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "remove_redundant_columns",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# (1 Point) `remove_redundant_columns`: Test cell 2\n",
    "assert tibbles_are_equivalent(remove_redundant_columns(baseball), -8278288771535832348), \"Tibbles don't match!\" \n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Great! If the above test case passed then let's remove columns from the original dataset `df` using `remove_redundant_columns(baseball)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101766, 37)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_test = remove_redundant_columns(baseball_test)\n",
    "baseball = remove_redundant_columns(baseball)\n",
    "baseball.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Shrinking the dataset.\n",
    "\n",
    "**Exercise 1** (1 point). Write a function `shrink_data()` which takes the dataframe `df` and returns a **new** dataframe where:\n",
    "\n",
    "* the column `yearID` should be converted to `pandas datetime` format; **and**\n",
    "* only rows such that `yearID` is from 2000 (inclusive) to 2016 (inclusive) are returned.\n",
    "\n",
    "> Hint: Regarding the first condition, see [`pandas.to_datetime()`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_datetime.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def shrink_data(df):\n",
    "    df_copy=df.copy()\n",
    "    df_copy['yearID']=pd.to_datetime(df_copy['yearID'],errors='coerce')\n",
    "    #print(df_copy)\n",
    "    df_copy2=df_copy[df_copy['yearID']>=pd.to_datetime('2000-01-01')]\n",
    "    df_copy3=df_copy2[df_copy2['yearID']<pd.to_datetime('2017-01-01')]\n",
    "    #print(df_copy)\n",
    "    return df_copy3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The test below will test your solution on a the smaller sample `baseball_test`. \n",
    "\n",
    "**Note**: The below test case is designed just for the purpose of debugging and will not be used for grading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "shrink_data_dummy",
     "locked": true,
     "points": "0",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# (0 Points) `shrink_data_dummy`:  Test cell 1\n",
    "\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "\n",
    "df_ex1_soln_instructor = canonicalize_tibble(pd.read_csv('ex1_soln.csv', parse_dates=['yearID']))\n",
    "df_ex1_soln_yours = canonicalize_tibble(shrink_data(baseball_test))\n",
    "\n",
    "assert type(df_ex1_soln_yours) == type(df_ex1_soln_instructor), 'Your output does not return a pandas dataframe'\n",
    "assert_frame_equal(df_ex1_soln_instructor, df_ex1_soln_yours)\n",
    "\n",
    "print('Passed!')\n",
    "del df_ex1_soln_instructor\n",
    "del df_ex1_soln_yours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Testing solution on original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "shrink_data",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# (1 Points) `shrink_data`: Test cell\n",
    "assert tibbles_are_equivalent(shrink_data(baseball), 1828659959833542576), \"Tibbles don't match!\" \n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's shrink the orginial dataframe now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31805, 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_test = shrink_data(baseball_test)\n",
    "baseball = shrink_data(baseball)\n",
    "baseball.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Several players appear in the dataset more than once. This is because they played for one team, then were traded or moved to another. Currently, the combination of `playerID`, `stint`, and `teamID` is unique within each row. We want to transform this into a dataset that contains the all _minimum_ characteristics of each player over all the teams and stints the player had.\n",
    "\n",
    "**Exercise 2** (3 points). Complete the function `transform_baseball_data(df)` and return a **new** dataframe such that, for each unique player (`playerID`):\n",
    "- only the earliest `yearID` is retained;\n",
    "- only the _lowest_ value of every numerical column is retained;\n",
    "- the columns `stint` and `teamID` are not retained;\n",
    "- after tranformation the numerical values are rounded to nearest 10 and converted to integer. For example, the value 15.33 rounded to nearest 10 is 20, and the value 14.999 is rounded to 10. For cases like 5, 15, 25, etc., such a value `v` would be the same as that produced by `round(v, -1)` in standard Python.\n",
    "\n",
    "The final data frame will have one row per unique player with the columns retained and transformed as outlined above.\n",
    "\n",
    "A natural way to start is to group the data frame `df` by `playerID`. However, for your final result, be sure that `playerID` is **not** the index. (That is, be sure your final result is a tibble.)\n",
    "\n",
    "> Hint: A relatively clean solution may be had by exploiting features of the [`.agg()` method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.agg.html) available for `.groupby()` objects produced when called on `DataFrame` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_baseball_data(df):\n",
    "    df_copy=df.copy()\n",
    "    \n",
    "    #Grouping by playerID, with minimum being applied\n",
    "    newdf=df_copy.groupby('playerID').agg(min)\n",
    "    \n",
    "    #Drop stint and teamID columns from df\n",
    "    newdf.drop(['stint','teamID'],axis=1,inplace=True)\n",
    "    newdf.reset_index(inplace=True)\n",
    "    newdf.rename({\"\":\"playerID\"},axis=1,inplace=True)\n",
    "    \n",
    "    #Round numerical rows\n",
    "    newdf.iloc[:,2:]=round(newdf.iloc[:,2:],-1).astype(int)\n",
    "    \n",
    "    #Convert numerical columns to integers\n",
    "    #newdf[list(\"ABCD\")] = df[list(\"ABCD\")].astype(int)\n",
    "\n",
    "\n",
    "    return newdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mine:\n",
      "      1B  2B  3B   AB  BA  BAPIP  BB  BB%  BB/K  CS    ...      SB%  SF  SH  \\\n",
      "0      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "1      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "2      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "3      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "4      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "5      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "6      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "7      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "8      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "9      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "10     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "11     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "12     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "13     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "14     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "15     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "16     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "17     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "18     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "19     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "20     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "21     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "22     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "23     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "24     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "25     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "26     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "27     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "28     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "29     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "..   ...  ..  ..  ...  ..    ...  ..  ...   ...  ..    ...      ...  ..  ..   \n",
      "128   10   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "129   10   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "130   10   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "131   10   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "132   10   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "133   10   0   0   40   0      0   0    0     0   0    ...        0   0   0   \n",
      "134   10   0   0   50   0      0   0    0     0   0    ...        0   0   0   \n",
      "135   10  10   0    0   0      0  10    0     0   0    ...        0   0   0   \n",
      "136   20   0   0    0   0      0  10    0     0   0    ...        0   0   0   \n",
      "137   30   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "138   30   0   0  150   0      0  20    0     0   0    ...        0   0   0   \n",
      "139   40   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "140   40  10   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "141   40  10   0  210   0      0   0    0     0   0    ...        0   0  10   \n",
      "142   50   0   0  190   0      0  20    0     0   0    ...        0   0   0   \n",
      "143   60   0  10  550   0      0  40    0     0   0    ...        0   0   0   \n",
      "144   80   0   0    0   0      0  40    0     0   0    ...        0   0  10   \n",
      "145   80  10   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "146   90   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "147   90   0   0  340   0      0   0    0     0   0    ...        0   0  30   \n",
      "148   90   0   0  470   0      0  20    0     0   0    ...        0   0   0   \n",
      "149  100   0   0    0   0      0  40    0     0   0    ...        0   0  50   \n",
      "150  100   0   0  550   0      0  30    0     0   0    ...        0   0  60   \n",
      "151  100  20  10  460   0      0  20    0     0   0    ...        0  10   0   \n",
      "152  120   0   0    0   0      0  40    0     0   0    ...        0  10   0   \n",
      "153  120   0   0  520   0      0   0    0     0   0    ...        0   0   0   \n",
      "154  120  10  10    0   0      0   0    0     0   0    ...        0   0  20   \n",
      "155  130  20   0    0   0      0  20    0     0   0    ...        0   0   0   \n",
      "156  130  20   0    0   0      0  50    0     0   0    ...        0   0  20   \n",
      "157  140   0   0    0   0      0  10    0     0  20    ...        0   0   0   \n",
      "\n",
      "     SLG  SO   TB  Weight  Weighted162Factor   playerID     yearID  \n",
      "0      0   0    0       0                  0  atchisc01 2010-01-01  \n",
      "1      0   0    0       0                  0  chacijh01 2010-01-01  \n",
      "2      0   0    0       0                  0  chanees01 2013-01-01  \n",
      "3      0   0    0       0                  0  danksjo01 2011-01-01  \n",
      "4      0   0    0       0                  0  finlech01 2002-01-01  \n",
      "5      0   0    0       0                  0  francje01 2011-01-01  \n",
      "6      0   0    0       0                  0  gagneer01 2007-01-01  \n",
      "7      0   0    0       0                  0  lairdge01 2015-01-01  \n",
      "8      0   0    0       0                  0  mathisc01 2011-01-01  \n",
      "9      0   0    0       0                  0  maurebr01 2014-01-01  \n",
      "10     0   0    0       0                  0  mccarbi02 2006-01-01  \n",
      "11     0   0    0       0                  0  mccarbr01 2012-01-01  \n",
      "12     0   0    0       0                  0  mulhote01 2001-01-01  \n",
      "13     0   0    0       0                  0  parnebo01 2011-01-01  \n",
      "14     0   0    0       0                  0  pegueja01 2008-01-01  \n",
      "15     0   0    0       0                  0  pomerst01 2012-01-01  \n",
      "16     0   0    0       0                  0  sanchan02 2013-01-01  \n",
      "17     0   0    0       0                  0  spoonti01 2003-01-01  \n",
      "18     0   0    0       0                  0  valenjo04 2004-01-01  \n",
      "19     0   0    0       0                  0  wengedo01 2001-01-01  \n",
      "20     0   0    0       0                 10  olivejo01 2001-01-01  \n",
      "21     0   0    0       0                 10  weathda01 2003-01-01  \n",
      "22     0   0    0     160                  0  gordoto01 2009-01-01  \n",
      "23     0   0    0     180                  0  burrebr01 2011-01-01  \n",
      "24     0   0    0     180                  0  johnsty01 2006-01-01  \n",
      "25     0   0    0     190                  0  callami01 2004-01-01  \n",
      "26     0   0    0     190                  0  castrmi01 2015-01-01  \n",
      "27     0   0    0     190                  0    foxma01 2010-01-01  \n",
      "28     0   0    0     200                  0  bluejji01 2016-01-01  \n",
      "29     0   0    0     200                  0  clippty01 2010-01-01  \n",
      "..   ...  ..  ...     ...                ...        ...        ...  \n",
      "128    0  10   10     190                  0  barfijo02 2009-01-01  \n",
      "129    0  10    0     210                  0  morrima01 2007-01-01  \n",
      "130    0   0    0       0                  0  keatira01 2014-01-01  \n",
      "131    0   0    0     200                  0  holadbr01 2013-01-01  \n",
      "132    0   0    0       0                  0  mcginjo01 2008-01-01  \n",
      "133    0  10   10       0                  0  kommefr01 2014-01-01  \n",
      "134    0   0    0     230                  0   belljo01 2012-01-01  \n",
      "135    0  10    0       0                  0  bartoda02 2007-01-01  \n",
      "136    0  10   20       0                 10  granted01 2013-01-01  \n",
      "137    0   0   60       0                  0   zinngu01 2013-01-01  \n",
      "138    0   0    0     190                  0  colembo01 2014-01-01  \n",
      "139    0   0   60       0                  0    leewa01 2003-01-01  \n",
      "140    0  60   90     220                  0  middlwi01 2015-01-01  \n",
      "141    0   0   80     180                  0  huntene01 2011-01-01  \n",
      "142    0   0    0       0                 10  sweenbi02 2007-01-01  \n",
      "143    0   0  280     220                  0  duvalad01 2016-01-01  \n",
      "144    0   0    0     170                  0  delahji01 2006-01-01  \n",
      "145    0   0    0     180                  0  mowremi01 2012-01-01  \n",
      "146    0   0  220       0                  0  jonesad01 2009-01-01  \n",
      "147    0   0  110       0                  0  myersha01 2015-01-01  \n",
      "148    0  50    0     180                 10  izturce01 2010-01-01  \n",
      "149    0   0  170       0                  0  ganlebo01 2008-01-01  \n",
      "150    0   0    0       0                  0  bradlbi01 2008-01-01  \n",
      "151    0  90    0     210                 10  parrage01 2009-01-01  \n",
      "152    0   0  340     220                  0  beltrad01 2012-01-01  \n",
      "153    0   0    0       0                 10  koneted01 2010-01-01  \n",
      "154    0  40    0     180                  0  mitchmi01 2012-01-01  \n",
      "155    0   0    0     180                 10  anderjo01 2006-01-01  \n",
      "156    0   0    0     160                  0  hemphch01 2007-01-01  \n",
      "157    0   0  250     190                  0  roberda01 2016-01-01  \n",
      "\n",
      "[158 rows x 35 columns]\n",
      "desired: \n",
      "      1B  2B  3B   AB  BA  BAPIP  BB  BB%  BB/K  CS    ...      SB%  SF  SH  \\\n",
      "0      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "1      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "2      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "3      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "4      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "5      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "6      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "7      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "8      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "9      0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "10     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "11     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "12     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "13     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "14     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "15     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "16     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "17     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "18     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "19     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "20     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "21     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "22     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "23     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "24     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "25     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "26     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "27     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "28     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "29     0   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "..   ...  ..  ..  ...  ..    ...  ..  ...   ...  ..    ...      ...  ..  ..   \n",
      "128   10   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "129   10   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "130   10   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "131   10   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "132   10   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "133   10   0   0   40   0      0   0    0     0   0    ...        0   0   0   \n",
      "134   10   0   0   50   0      0   0    0     0   0    ...        0   0   0   \n",
      "135   10  10   0    0   0      0  10    0     0   0    ...        0   0   0   \n",
      "136   20   0   0    0   0      0  10    0     0   0    ...        0   0   0   \n",
      "137   30   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "138   30   0   0  150   0      0  20    0     0   0    ...        0   0   0   \n",
      "139   40   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "140   40  10   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "141   40  10   0  210   0      0   0    0     0   0    ...        0   0  10   \n",
      "142   50   0   0  190   0      0  20    0     0   0    ...        0   0   0   \n",
      "143   60   0  10  550   0      0  40    0     0   0    ...        0   0   0   \n",
      "144   80   0   0    0   0      0  40    0     0   0    ...        0   0  10   \n",
      "145   80  10   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "146   90   0   0    0   0      0   0    0     0   0    ...        0   0   0   \n",
      "147   90   0   0  340   0      0   0    0     0   0    ...        0   0  30   \n",
      "148   90   0   0  470   0      0  20    0     0   0    ...        0   0   0   \n",
      "149  100   0   0    0   0      0  40    0     0   0    ...        0   0  50   \n",
      "150  100   0   0  550   0      0  30    0     0   0    ...        0   0  60   \n",
      "151  100  20  10  460   0      0  20    0     0   0    ...        0  10   0   \n",
      "152  120   0   0    0   0      0  40    0     0   0    ...        0  10   0   \n",
      "153  120   0   0  520   0      0   0    0     0   0    ...        0   0   0   \n",
      "154  120  10  10    0   0      0   0    0     0   0    ...        0   0  20   \n",
      "155  130  20   0    0   0      0  20    0     0   0    ...        0   0   0   \n",
      "156  130  20   0    0   0      0  50    0     0   0    ...        0   0  20   \n",
      "157  140   0   0    0   0      0  10    0     0  20    ...        0   0   0   \n",
      "\n",
      "     SLG  SO   TB  Weight  Weighted162Factor   playerID     yearID  \n",
      "0      0   0    0       0                  0  atchisc01 2010-01-01  \n",
      "1      0   0    0       0                  0  chacijh01 2010-01-01  \n",
      "2      0   0    0       0                  0  chanees01 2013-01-01  \n",
      "3      0   0    0       0                  0  danksjo01 2011-01-01  \n",
      "4      0   0    0       0                  0  finlech01 2002-01-01  \n",
      "5      0   0    0       0                  0  francje01 2011-01-01  \n",
      "6      0   0    0       0                  0  gagneer01 2007-01-01  \n",
      "7      0   0    0       0                  0  lairdge01 2015-01-01  \n",
      "8      0   0    0       0                  0  mathisc01 2011-01-01  \n",
      "9      0   0    0       0                  0  maurebr01 2014-01-01  \n",
      "10     0   0    0       0                  0  mccarbi02 2006-01-01  \n",
      "11     0   0    0       0                  0  mccarbr01 2012-01-01  \n",
      "12     0   0    0       0                  0  mulhote01 2001-01-01  \n",
      "13     0   0    0       0                  0  parnebo01 2011-01-01  \n",
      "14     0   0    0       0                  0  pegueja01 2008-01-01  \n",
      "15     0   0    0       0                  0  pomerst01 2012-01-01  \n",
      "16     0   0    0       0                  0  sanchan02 2013-01-01  \n",
      "17     0   0    0       0                  0  spoonti01 2003-01-01  \n",
      "18     0   0    0       0                  0  valenjo04 2004-01-01  \n",
      "19     0   0    0       0                  0  wengedo01 2001-01-01  \n",
      "20     0   0    0       0                 10  olivejo01 2001-01-01  \n",
      "21     0   0    0       0                 10  weathda01 2003-01-01  \n",
      "22     0   0    0     160                  0  gordoto01 2009-01-01  \n",
      "23     0   0    0     180                  0  burrebr01 2011-01-01  \n",
      "24     0   0    0     180                  0  johnsty01 2006-01-01  \n",
      "25     0   0    0     190                  0  callami01 2004-01-01  \n",
      "26     0   0    0     190                  0  castrmi01 2015-01-01  \n",
      "27     0   0    0     190                  0    foxma01 2010-01-01  \n",
      "28     0   0    0     200                  0  bluejji01 2016-01-01  \n",
      "29     0   0    0     200                  0  clippty01 2010-01-01  \n",
      "..   ...  ..  ...     ...                ...        ...        ...  \n",
      "128    0  10   10     190                  0  barfijo02 2009-01-01  \n",
      "129    0  10    0     210                  0  morrima01 2007-01-01  \n",
      "130    0   0    0       0                  0  keatira01 2014-01-01  \n",
      "131    0   0    0     200                  0  holadbr01 2013-01-01  \n",
      "132    0   0    0       0                  0  mcginjo01 2008-01-01  \n",
      "133    0  10   10       0                  0  kommefr01 2014-01-01  \n",
      "134    0   0    0     230                  0   belljo01 2012-01-01  \n",
      "135    0  10    0       0                  0  bartoda02 2007-01-01  \n",
      "136    0  10   20       0                 10  granted01 2013-01-01  \n",
      "137    0   0   60       0                  0   zinngu01 2013-01-01  \n",
      "138    0   0    0     190                  0  colembo01 2014-01-01  \n",
      "139    0   0   60       0                  0    leewa01 2003-01-01  \n",
      "140    0  60   90     220                  0  middlwi01 2015-01-01  \n",
      "141    0   0   80     180                  0  huntene01 2011-01-01  \n",
      "142    0   0    0       0                 10  sweenbi02 2007-01-01  \n",
      "143    0   0  280     220                  0  duvalad01 2016-01-01  \n",
      "144    0   0    0     170                  0  delahji01 2006-01-01  \n",
      "145    0   0    0     180                  0  mowremi01 2012-01-01  \n",
      "146    0   0  220       0                  0  jonesad01 2009-01-01  \n",
      "147    0   0  110       0                  0  myersha01 2015-01-01  \n",
      "148    0  50    0     180                 10  izturce01 2010-01-01  \n",
      "149    0   0  170       0                  0  ganlebo01 2008-01-01  \n",
      "150    0   0    0       0                  0  bradlbi01 2008-01-01  \n",
      "151    0  90    0     210                 10  parrage01 2009-01-01  \n",
      "152    0   0  340     220                  0  beltrad01 2012-01-01  \n",
      "153    0   0    0       0                 10  koneted01 2010-01-01  \n",
      "154    0  40    0     180                  0  mitchmi01 2012-01-01  \n",
      "155    0   0    0     180                 10  anderjo01 2006-01-01  \n",
      "156    0   0    0     160                  0  hemphch01 2007-01-01  \n",
      "157    0   0  250     190                  0  roberda01 2016-01-01  \n",
      "\n",
      "[158 rows x 35 columns]\n",
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# (0 Points) `transform_baseball_data_dummy`: Test cell\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "\n",
    "df_ex2_soln_instructor = canonicalize_tibble(pd.read_csv('ex2_soln.csv', parse_dates=['yearID']))\n",
    "df_ex2_soln_yours = canonicalize_tibble(transform_baseball_data(baseball_test))\n",
    "\n",
    "print('mine:')\n",
    "print(df_ex2_soln_yours)\n",
    "\n",
    "print('desired: ')\n",
    "print(df_ex2_soln_instructor)\n",
    "\n",
    "assert type(df_ex2_soln_yours) == type(df_ex2_soln_instructor), 'Your output does not return a pandas dataframe'\n",
    "assert_frame_equal(df_ex2_soln_instructor, df_ex2_soln_yours)\n",
    "\n",
    "print('Passed!')\n",
    "del df_ex2_soln_instructor\n",
    "del df_ex2_soln_yours\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "To test your solution we have provided solution for the dataframe `baseball_test` \n",
    "\n",
    "**Note**: The below test case is designed just to help you debug. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "transform_baseball_data_dummy",
     "locked": true,
     "points": "0",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# (0 Points) `transform_baseball_data_dummy`: Test cell\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "\n",
    "df_ex2_soln_instructor = canonicalize_tibble(pd.read_csv('ex2_soln.csv', parse_dates=['yearID']))\n",
    "df_ex2_soln_yours = canonicalize_tibble(transform_baseball_data(baseball_test))\n",
    "\n",
    "assert type(df_ex2_soln_yours) == type(df_ex2_soln_instructor), 'Your output does not return a pandas dataframe'\n",
    "assert_frame_equal(df_ex2_soln_instructor, df_ex2_soln_yours)\n",
    "\n",
    "print('Passed!')\n",
    "del df_ex2_soln_instructor\n",
    "del df_ex2_soln_yours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Testing on original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "transform_baseball_data",
     "locked": true,
     "points": "3",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# (3 Points) `transform_baseball_data`: Test cell\n",
    "assert tibbles_are_equivalent(baseball, 1828659959833542576), \"Tibbles don't match!\" \n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's transform the original dataframe `baseball`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7403, 35)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_test = transform_baseball_data(baseball_test)\n",
    "baseball = transform_baseball_data(baseball)\n",
    "baseball.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Faster matrix products\n",
    "\n",
    "Now, we're going to change direction just a little. Don't worry, you don't need to know anything conceptual about what we're about to do; all you need to do is think of a faster way to apply the formula to generate its output based on the course material that's already been covered.\n",
    "\n",
    "One way of calculating the variance matrix $\\Sigma$ of a dataset is given by the formula\n",
    "\n",
    "$$\\Sigma=E(XX^T)-\\mu\\mu^T$$\n",
    "\n",
    "where $X$ is an $n \\times m$ matrix containing each data point and $\\mu$ is an $n \\times m$ matrix containing the column means of those data points.\n",
    "\n",
    "For this exercise, we will simply be calculating the parameter given to the expectation $E(\\cdot)$ function, $XX^T$. You can see in the cell below that this has already been done for you, but your task will be to figure out how to run `X.dot(X.T)` faster than we did.\n",
    "\n",
    "First, run the code cell below to establish an estimate time for the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix X is of size (7403, 33)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "X = baseball[[x for x in baseball.columns if x not in ['playerID','yearID']]].values\n",
    "\n",
    "print(\"Matrix X is of size {}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your estimated time for X.dot(X.T) is  4.7609 seconds.\n"
     ]
    }
   ],
   "source": [
    "def slow_calc(X):\n",
    "    return X.dot(X.T)\n",
    "\n",
    "slow_time = timeit.timeit(\"slow_calc(X)\",setup=\"from __main__ import slow_calc, X\", number = 1)\n",
    "print(\"Your estimated time for X.dot(X.T) is \"+' {0:.4f}'.format(slow_time) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 3** (5 points): Come up with a way to make the matrix-times-transpose function faster than `slow_calc(X)`. Implement your method as the function `fast_calc()`. To get the full 5 points, your method must be **2.5 times faster**. You can get partial credit: 3 points if your function is at least 2 times faster and 1 point if your function is at least 1.5 times faster.\n",
    "\n",
    "The input to `fast_calc` is of type `numpy.ndarray` and expected output is also of type `numpy.ndarray`\n",
    "\n",
    "**Note**: The variable named `number_of_runs` determines how many times `fast_calc` will be run against the timer. You may lower `number_of_runs` for debugging purposes, but must increase it to at least 5 to pass the test cell. You may also import libraries you would like to use.\n",
    "\n",
    "**The benchmarks for this question are set according to Vocareum environment.** You might get different results if you test on your system. So please test your results here.\n",
    "\n",
    "> This exercise requires some creativity in thinking about how to exploit structure present in the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/9478791/is-there-an-enhanced-numpy-scipy-dot-method/9479621#9479621\n",
    "\n",
    "# http://www.benjaminjohnston.com.au/matmul\n",
    "\n",
    "# https://software.intel.com/en-us/node/696338\n",
    "\n",
    "number_of_runs = 5\n",
    "\n",
    "#print(X.flags)\n",
    "\n",
    "from scipy.linalg import blas as FB\n",
    "def fast_calc(X):\n",
    "    #changing dtype=np.float64 to dtype=np.float32 actually slows down the computation\n",
    "    #Xc=np.array(np.copy(X,order='C'))\n",
    "    \n",
    "    Xf=np.array(np.copy(X,order='F'),dtype=np.float32)\n",
    "    return FB.dgemm(alpha=1.0, a=Xf, b=Xf, trans_b=True)\n",
    "\n",
    "def fast_calc2(X):\n",
    "    return np.multiply(X,X.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this test to get on 1 point for a solution that is at least 1.5 times faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "speed_test_1",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your baseline time for X.dot(X.T) is 0.4594 seconds, which is 7.81 times faster than our method.\n",
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# (1 point) `speed_test_1`: Test cell\n",
    "for i in range(5):\n",
    "    nrows = np.random.randint(5) + 1\n",
    "    ncols = np.random.randint(5) + 1\n",
    "    A = np.random.rand(nrows, ncols)\n",
    "    your_out = fast_calc(A)\n",
    "    instructor_out = slow_calc(A)\n",
    "    assert type(your_out) == type(A), \"Please return object of type {}\".format(type(A))\n",
    "    np.testing.assert_array_almost_equal(instructor_out, your_out, decimal = 5)\n",
    "\n",
    "slow_time = timeit.timeit(\"slow_calc(X)\",setup=\"from __main__ import slow_calc, X\", number = number_of_runs)/number_of_runs\n",
    "student_time = timeit.timeit(\"fast_calc(X)\", setup=\"from __main__ import fast_calc, X\",number = number_of_runs)/number_of_runs\n",
    "print(\"Your baseline time for X.dot(X.T) is \"+'{0:.4f}'.format(student_time)+\" seconds, which is \"+'{0:.2f}'.format(slow_time/student_time)+ \" times faster than our method.\")\n",
    "assert student_time/slow_time <= 0.75, \"Your solution isn't at least 1.5 times faster than our solution.\"\n",
    "assert number_of_runs >= 5, \"number_of_runs needs to be >=5 to pass this cell.\"\n",
    "\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Run this test to get 2 points for a solution that is at least 2 times faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "speed_test_2",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your baseline time for X.dot(X.T) is 0.3327 seconds, which is 9.52 times faster than our method.\n",
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# (2 point) `speed_test_2`: Test cell\n",
    "for i in range(5):\n",
    "    nrows = np.random.randint(5) + 1\n",
    "    ncols = np.random.randint(5) + 1\n",
    "    A = np.random.rand(nrows, ncols)\n",
    "    your_out = fast_calc(A)\n",
    "    instructor_out = slow_calc(A)\n",
    "    assert type(your_out) == type(A), \"Please return object of type {}\".format(type(A))\n",
    "    np.testing.assert_array_almost_equal(instructor_out, your_out, decimal = 5)\n",
    "\n",
    "slow_time = timeit.timeit(\"slow_calc(X)\",setup=\"from __main__ import slow_calc, X\", number = number_of_runs)/number_of_runs\n",
    "student_time = timeit.timeit(\"fast_calc(X)\", setup=\"from __main__ import fast_calc, X\",number = number_of_runs)/number_of_runs\n",
    "print(\"Your baseline time for X.dot(X.T) is \"+'{0:.4f}'.format(student_time)+\" seconds, which is \"+'{0:.2f}'.format(slow_time/student_time)+ \" times faster than our method.\")\n",
    "assert student_time/slow_time <= 0.5, \"Your solution isn't at least 2 times faster than our solution.\"\n",
    "assert number_of_runs >= 5, \"number_of_runs needs to be >=5 to pass this cell.\"\n",
    "\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Run this test to get 2 points for a solution that is at least 2.5 times faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "speed_test_3",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your baseline time for X.dot(X.T) is 0.3698 seconds, which is 8.27 times faster than our method.\n",
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "# (2 point) `speed_test_3`: Test cell\n",
    "for i in range(5):\n",
    "    nrows = np.random.randint(5) + 1\n",
    "    ncols = np.random.randint(5) + 1\n",
    "    A = np.random.rand(nrows, ncols)\n",
    "    your_out = fast_calc(A)\n",
    "    instructor_out = slow_calc(A)\n",
    "    assert type(your_out) == type(A), \"Please return object of type {}\".format(type(A))\n",
    "    np.testing.assert_array_almost_equal(instructor_out, your_out, decimal = 5)\n",
    "\n",
    "slow_time = timeit.timeit(\"slow_calc(X)\",setup=\"from __main__ import slow_calc, X\", number = number_of_runs)/number_of_runs\n",
    "student_time = timeit.timeit(\"fast_calc(X)\", setup=\"from __main__ import fast_calc, X\",number = number_of_runs)/number_of_runs\n",
    "print(\"Your baseline time for X.dot(X.T) is \"+'{0:.4f}'.format(student_time)+\" seconds, which is \"+'{0:.2f}'.format(slow_time/student_time)+ \" times faster than our method.\")\n",
    "assert student_time/slow_time <= 0.40, \"Your solution isn't at least 2.5 times faster than our solution.\"\n",
    "assert number_of_runs >= 5, \"number_of_runs needs to be >=5 to pass this cell.\"\n",
    "\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Fin!** Remember to test your solutions by running them as the autograder will: restart the kernel and run all cells from \"top-to-bottom.\" Also remember to submit to the autograder; otherwise, you will **not** get credit for your hard work!"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
